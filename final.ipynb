{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c0b5735",
   "metadata": {
    "papermill": {
     "duration": 0.008672,
     "end_time": "2023-08-17T10:56:28.242924",
     "exception": false,
     "start_time": "2023-08-17T10:56:28.234252",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This notebook conduct dataset cleaning on CICIDS2017 in the following aspect:\n",
    "* remove space before each feature names\n",
    "* assign 0 for non-negative features when there is negative values\n",
    "* drop zero variance columns (only have 1 unique value)\n",
    "* remove inf, -inf, nan, and duplicate rows\n",
    "* drop columns with identical values\n",
    "\n",
    "However, two recent papers [1](#first), [2](#second) have been discussing that CIC-IDS-2017 and CSE-CIC-IDS-2018 have many errors throughout the dataset creation lifecycle, such as in attack orchestration, feature generation, documentation, and labeling.\n",
    "* Attack orchestration errors: These are errors that occur during the execution of the attack scenarios on the network.\n",
    "* Feature generation errors: These are errors that occur during the extraction of features from the network traffic using CICFlowMeter.\n",
    "* Documentation errors: These are errors that occur during the description and explanation of the datasets and their components. \n",
    "* Labeling errors: These are errors that occur during the assignment of labels to the network flows based on their class or category.\n",
    "\n",
    "[1](#first) have published their improved version of these two datasets [here](https://intrusion-detection.distrinet-research.be/CNS2022/Dataset_Download.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8590634",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-08-17T10:56:28.263148Z",
     "iopub.status.busy": "2023-08-17T10:56:28.262249Z",
     "iopub.status.idle": "2023-08-17T10:56:30.323818Z",
     "shell.execute_reply": "2023-08-17T10:56:30.322554Z"
    },
    "papermill": {
     "duration": 2.074522,
     "end_time": "2023-08-17T10:56:30.326501",
     "exception": false,
     "start_time": "2023-08-17T10:56:28.251979",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from itertools import combinations, product\n",
    "\n",
    "#sklearn\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, QuantileTransformer, MinMaxScaler\n",
    "from sklearn.metrics import precision_recall_curve, auc, roc_curve, recall_score, precision_score, f1_score\n",
    "\n",
    "#graph\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ce2f70",
   "metadata": {
    "papermill": {
     "duration": 0.00833,
     "end_time": "2023-08-17T10:56:30.343509",
     "exception": false,
     "start_time": "2023-08-17T10:56:30.335179",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Original CICIDS2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fcd3f531",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-17T10:56:30.361609Z",
     "iopub.status.busy": "2023-08-17T10:56:30.361177Z",
     "iopub.status.idle": "2023-08-17T10:56:59.627685Z",
     "shell.execute_reply": "2023-08-17T10:56:59.626722Z"
    },
    "papermill": {
     "duration": 29.278855,
     "end_time": "2023-08-17T10:56:59.630608",
     "exception": false,
     "start_time": "2023-08-17T10:56:30.351753",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_csv_path = '/Users/shreenidhishetty/Documents/ECC Project/MachineLearningCVE'\n",
    "csv_file_names = ['Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv', \n",
    "                  'Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv', \n",
    "                  'Friday-WorkingHours-Morning.pcap_ISCX.csv', \n",
    "                  'Monday-WorkingHours.pcap_ISCX.csv', \n",
    "                  'Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv', \n",
    "                  'Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv', \n",
    "                  'Tuesday-WorkingHours.pcap_ISCX.csv', \n",
    "                  'Wednesday-workingHours.pcap_ISCX.csv']\n",
    "\n",
    "complete_paths = []\n",
    "for csv_file_name in csv_file_names:\n",
    "    complete_paths.append(os.path.join(dataset_csv_path, csv_file_name))\n",
    "\n",
    "df = pd.concat(map(pd.read_csv, complete_paths), \n",
    "               ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ab09466",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-17T10:56:59.660630Z",
     "iopub.status.busy": "2023-08-17T10:56:59.659769Z",
     "iopub.status.idle": "2023-08-17T10:57:33.153154Z",
     "shell.execute_reply": "2023-08-17T10:57:33.151975Z"
    },
    "papermill": {
     "duration": 33.517199,
     "end_time": "2023-08-17T10:57:33.162670",
     "exception": false,
     "start_time": "2023-08-17T10:56:59.645471",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset shape (2830743, 79)\n",
      "zero variance columns ['Bwd PSH Flags', 'Bwd URG Flags', 'Fwd Avg Bytes/Bulk', 'Fwd Avg Packets/Bulk', 'Fwd Avg Bulk Rate', 'Bwd Avg Bytes/Bulk', 'Bwd Avg Packets/Bulk', 'Bwd Avg Bulk Rate'] dropped\n",
      "shape after removing zero variance columns: (2830743, 71)\n",
      "2867 rows dropped\n",
      "shape after removing nan: (2827876, 71)\n",
      "shape after dropping duplicates: (2520798, 71)\n",
      "columns which have identical values [('Total Fwd Packets', 'Subflow Fwd Packets'), ('Total Backward Packets', 'Subflow Bwd Packets'), ('Fwd PSH Flags', 'SYN Flag Count'), ('Fwd URG Flags', 'CWE Flag Count'), ('Fwd Header Length', 'Fwd Header Length.1')] dropped\n",
      "shape after removing identical value columns: (2520798, 66)\n"
     ]
    }
   ],
   "source": [
    "def clean_df(df):\n",
    "    # Remove the space before each feature names\n",
    "    df.columns = df.columns.str.strip()\n",
    "    print('dataset shape', df.shape)\n",
    "\n",
    "    # This set of feature should have >= 0 values\n",
    "    num = df._get_numeric_data()\n",
    "    num[num < 0] = 0\n",
    "\n",
    "    zero_variance_cols = []\n",
    "    for col in df.columns:\n",
    "        if len(df[col].unique()) == 1:\n",
    "            zero_variance_cols.append(col)\n",
    "    df.drop(zero_variance_cols, axis = 1, inplace = True)\n",
    "    print('zero variance columns', zero_variance_cols, 'dropped')\n",
    "    print('shape after removing zero variance columns:', df.shape)\n",
    "\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace = True)\n",
    "    print(df.isna().any(axis = 1).sum(), 'rows dropped')\n",
    "    df.dropna(inplace = True)\n",
    "    print('shape after removing nan:', df.shape)\n",
    "\n",
    "    # Drop duplicate rows\n",
    "    df.drop_duplicates(inplace = True)\n",
    "    print('shape after dropping duplicates:', df.shape)\n",
    "\n",
    "    column_pairs = [(i, j) for i, j in combinations(df, 2) if df[i].equals(df[j])]\n",
    "    ide_cols = []\n",
    "    for column_pair in column_pairs:\n",
    "        ide_cols.append(column_pair[1])\n",
    "    df.drop(ide_cols, axis = 1, inplace = True)\n",
    "    print('columns which have identical values', column_pairs, 'dropped')\n",
    "    print('shape after removing identical value columns:', df.shape)\n",
    "    return df\n",
    "df = clean_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0925d19b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-17T10:57:33.181532Z",
     "iopub.status.busy": "2023-08-17T10:57:33.180789Z",
     "iopub.status.idle": "2023-08-17T10:57:33.381214Z",
     "shell.execute_reply": "2023-08-17T10:57:33.380494Z"
    },
    "papermill": {
     "duration": 0.211991,
     "end_time": "2023-08-17T10:57:33.383132",
     "exception": false,
     "start_time": "2023-08-17T10:57:33.171141",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BENIGN                        2095057\n",
       "DoS Hulk                       172846\n",
       "DDoS                           128014\n",
       "PortScan                        90694\n",
       "DoS GoldenEye                   10286\n",
       "FTP-Patator                      5931\n",
       "DoS slowloris                    5385\n",
       "DoS Slowhttptest                 5228\n",
       "SSH-Patator                      3219\n",
       "Bot                              1948\n",
       "Web Attack � Brute Force         1470\n",
       "Web Attack � XSS                  652\n",
       "Infiltration                       36\n",
       "Web Attack � Sql Injection         21\n",
       "Heartbleed                         11\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5de67f2",
   "metadata": {
    "papermill": {
     "duration": 0.008441,
     "end_time": "2023-08-17T10:57:33.400233",
     "exception": false,
     "start_time": "2023-08-17T10:57:33.391792",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Improved CICIDS2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "753fcc49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-17T10:57:33.419454Z",
     "iopub.status.busy": "2023-08-17T10:57:33.418777Z",
     "iopub.status.idle": "2023-08-17T10:58:06.350399Z",
     "shell.execute_reply": "2023-08-17T10:58:06.349285Z"
    },
    "papermill": {
     "duration": 32.944146,
     "end_time": "2023-08-17T10:58:06.352979",
     "exception": false,
     "start_time": "2023-08-17T10:57:33.408833",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_csv_path = '/Users/shreenidhishetty/Documents/ECC Project/CICIDS2017_improved'\n",
    "csv_file_names = ['monday.csv', \n",
    "                  'tuesday.csv', \n",
    "                  'wednesday.csv', \n",
    "                  'thursday.csv', \n",
    "                  'friday.csv']\n",
    "\n",
    "complete_paths = []\n",
    "for csv_file_name in csv_file_names:\n",
    "    complete_paths.append(os.path.join(dataset_csv_path, csv_file_name))\n",
    "\n",
    "improved_df = pd.concat(map(pd.read_csv, complete_paths), \n",
    "                        ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c3dbd12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-17T10:58:06.372091Z",
     "iopub.status.busy": "2023-08-17T10:58:06.371730Z",
     "iopub.status.idle": "2023-08-17T10:58:48.234875Z",
     "shell.execute_reply": "2023-08-17T10:58:48.233955Z"
    },
    "papermill": {
     "duration": 41.874978,
     "end_time": "2023-08-17T10:58:48.236903",
     "exception": false,
     "start_time": "2023-08-17T10:58:06.361925",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset shape (2099976, 91)\n",
      "zero variance columns [] dropped\n",
      "shape after removing zero variance columns: (2099976, 91)\n",
      "5 rows dropped\n",
      "shape after removing nan: (2099971, 91)\n",
      "shape after dropping duplicates: (2099971, 91)\n",
      "columns which have identical values [] dropped\n",
      "shape after removing identical value columns: (2099971, 91)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BENIGN                                    1582561\n",
       "Portscan                                   159066\n",
       "DoS Hulk                                   158468\n",
       "DDoS                                        95144\n",
       "Infiltration - Portscan                     71767\n",
       "DoS GoldenEye                                7567\n",
       "Botnet - Attempted                           4067\n",
       "FTP-Patator                                  3972\n",
       "DoS Slowloris                                3859\n",
       "DoS Slowhttptest - Attempted                 3368\n",
       "SSH-Patator                                  2961\n",
       "DoS Slowloris - Attempted                    1847\n",
       "DoS Slowhttptest                             1740\n",
       "Web Attack - Brute Force - Attempted         1292\n",
       "Botnet                                        736\n",
       "Web Attack - XSS - Attempted                  655\n",
       "DoS Hulk - Attempted                          581\n",
       "DoS GoldenEye - Attempted                      80\n",
       "Web Attack - Brute Force                       73\n",
       "Infiltration - Attempted                       45\n",
       "Infiltration                                   36\n",
       "SSH-Patator - Attempted                        27\n",
       "Web Attack - XSS                               18\n",
       "Web Attack - SQL Injection                     13\n",
       "FTP-Patator - Attempted                        12\n",
       "Heartbleed                                     11\n",
       "Web Attack - SQL Injection - Attempted          5\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropping_cols = ['id', 'Flow ID', 'Src IP', 'Src Port', 'Dst IP', \n",
    "                 'Dst Port', 'Timestamp']\n",
    "improved_df = clean_df(improved_df)\n",
    "improved_df.drop(dropping_cols, axis = 1, inplace = True)\n",
    "improved_df['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4cabd1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-17T10:58:48.256842Z",
     "iopub.status.busy": "2023-08-17T10:58:48.256494Z",
     "iopub.status.idle": "2023-08-17T10:58:48.427299Z",
     "shell.execute_reply": "2023-08-17T10:58:48.426319Z"
    },
    "papermill": {
     "duration": 0.183035,
     "end_time": "2023-08-17T10:58:48.429394",
     "exception": false,
     "start_time": "2023-08-17T10:58:48.246359",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "improved_df['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d04890",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-17T10:58:48.449989Z",
     "iopub.status.busy": "2023-08-17T10:58:48.449646Z",
     "iopub.status.idle": "2023-08-17T10:58:48.479426Z",
     "shell.execute_reply": "2023-08-17T10:58:48.478343Z"
    },
    "papermill": {
     "duration": 0.042493,
     "end_time": "2023-08-17T10:58:48.481549",
     "exception": false,
     "start_time": "2023-08-17T10:58:48.439056",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "improved_df['Attempted Category'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c91c7e",
   "metadata": {
    "papermill": {
     "duration": 0.009042,
     "end_time": "2023-08-17T10:58:48.500018",
     "exception": false,
     "start_time": "2023-08-17T10:58:48.490976",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Although the flows of attempted attacks have malicious intents,they don't have anomaly effect on the system due to the following reasons [3](#third):\n",
    "* Category 0 - No payload sent by attacker\n",
    "* Category 1 - Port/System closed\n",
    "* Category 2 - Attack Startup/Teardown Artefact\n",
    "* Category 3 - No malicious payload\n",
    "* Category 4 - Attack Artefact\n",
    "* Category 5 - Attack Implemented Incorrectly\n",
    "* Category 6 - Target System Unresponsive\n",
    "\n",
    "For these kinds of attempted labels, we have a choice to treat them as benign or malicious.\n",
    "\n",
    "In most cases of network intrusion detection, we process each flow separately, so the classifier can only see only flow at a time and doesn't know the context.\n",
    "\n",
    "As a result, they are re-labeled as BENIGN [4](#fourth)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72643079",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-17T10:58:48.519904Z",
     "iopub.status.busy": "2023-08-17T10:58:48.519557Z",
     "iopub.status.idle": "2023-08-17T10:58:50.317529Z",
     "shell.execute_reply": "2023-08-17T10:58:50.316453Z"
    },
    "papermill": {
     "duration": 1.811037,
     "end_time": "2023-08-17T10:58:50.320156",
     "exception": false,
     "start_time": "2023-08-17T10:58:48.509119",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "attepmted_labels = [s for s in improved_df['Label'].unique() if 'Attempted' in s]\n",
    "\n",
    "improved_df.drop(['Attempted Category'], axis = 1, inplace = True)\n",
    "\n",
    "improved_df.replace(attepmted_labels, 'BENIGN', inplace = True)\n",
    "improved_df['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64964ee9",
   "metadata": {
    "papermill": {
     "duration": 0.00918,
     "end_time": "2023-08-17T10:58:50.338794",
     "exception": false,
     "start_time": "2023-08-17T10:58:50.329614",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 2D-PCA visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d99d97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-17T10:58:50.359500Z",
     "iopub.status.busy": "2023-08-17T10:58:50.358772Z",
     "iopub.status.idle": "2023-08-17T10:59:06.155344Z",
     "shell.execute_reply": "2023-08-17T10:59:06.154233Z"
    },
    "papermill": {
     "duration": 15.810728,
     "end_time": "2023-08-17T10:59:06.158811",
     "exception": false,
     "start_time": "2023-08-17T10:58:50.348083",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/43640952/how-to-subsample-a-pandas-dataframe-respecting-the-frequency-of-each-class\n",
    "subsample_df = df.groupby('Label').apply(pd.DataFrame.sample, frac = 0.1).reset_index(drop = True)\n",
    "\n",
    "X = subsample_df.drop(['Label'], axis = 1)\n",
    "y = subsample_df['Label']\n",
    "\n",
    "pca = PCA(n_components = 2, random_state = 0)\n",
    "z = pca.fit_transform(X) \n",
    "\n",
    "pca_15_df = pd.DataFrame()\n",
    "pca_15_df['Label'] = y\n",
    "pca_15_df['dimension 1'] = z[:, 0]\n",
    "pca_15_df['dimension 2'] = z[:, 1]\n",
    "\n",
    "sns.scatterplot(x = 'dimension 1', y = 'dimension 2', \n",
    "                hue = pca_15_df.Label,\n",
    "                palette = sns.color_palette('deep', len(pca_15_df.Label.value_counts())),\n",
    "                data = pca_15_df).set(title = 'CICIDS2017 15 Classes PCA Projection')\n",
    "plt.legend(loc = 'center left', bbox_to_anchor = (1, 0.5)) \n",
    "plt.show()\n",
    "\n",
    "pca_2_df = pd.DataFrame()\n",
    "pca_2_df['Label'] = y\n",
    "pca_2_df.loc[pca_2_df.Label != 'BENIGN', 'Label'] = 'ATTACK'\n",
    "pca_2_df['dimension 1'] = z[:, 0]\n",
    "pca_2_df['dimension 2'] = z[:, 1]\n",
    "\n",
    "sns.scatterplot(x = 'dimension 1', y = 'dimension 2', \n",
    "                hue = pca_2_df.Label,\n",
    "                palette = sns.color_palette('deep', 2),\n",
    "                data = pca_2_df).set(title = 'CICIDS2017 Binary Classes PCA Projection') \n",
    "plt.legend(loc = 'center left', bbox_to_anchor = (1, 0.5)) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198d60bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-17T10:59:06.191417Z",
     "iopub.status.busy": "2023-08-17T10:59:06.190307Z",
     "iopub.status.idle": "2023-08-17T10:59:19.860203Z",
     "shell.execute_reply": "2023-08-17T10:59:19.859355Z"
    },
    "papermill": {
     "duration": 13.688456,
     "end_time": "2023-08-17T10:59:19.862548",
     "exception": false,
     "start_time": "2023-08-17T10:59:06.174092",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "subsample_improved_df = improved_df.groupby('Label').apply(pd.DataFrame.sample, frac = 0.1).reset_index(drop = True)\n",
    "\n",
    "X = subsample_improved_df.drop(['Label'], axis = 1)\n",
    "y = subsample_improved_df['Label']\n",
    "\n",
    "pca = PCA(n_components = 2, random_state = 0)\n",
    "z = pca.fit_transform(X) \n",
    "\n",
    "pca_15_df = pd.DataFrame()\n",
    "pca_15_df['Label'] = y\n",
    "pca_15_df['dimension 1'] = z[:, 0]\n",
    "pca_15_df['dimension 2'] = z[:, 1]\n",
    "\n",
    "sns.scatterplot(x = 'dimension 1', y = 'dimension 2', \n",
    "                hue = pca_15_df.Label,\n",
    "                palette = sns.color_palette('deep', len(pca_15_df.Label.value_counts())),\n",
    "                data = pca_15_df).set(title = 'Improved CICIDS2017 15 Classes PCA Projection')\n",
    "plt.legend(loc = 'center left', bbox_to_anchor = (1, 0.5)) \n",
    "plt.show()\n",
    "\n",
    "pca_2_df = pd.DataFrame()\n",
    "pca_2_df['Label'] = y\n",
    "pca_2_df.loc[pca_2_df.Label != 'BENIGN', 'Label'] = 'ATTACK'\n",
    "pca_2_df['dimension 1'] = z[:, 0]\n",
    "pca_2_df['dimension 2'] = z[:, 1]\n",
    "\n",
    "sns.scatterplot(x = 'dimension 1', y = 'dimension 2', \n",
    "                hue = pca_2_df.Label,\n",
    "                palette = sns.color_palette('deep', 2),\n",
    "                data = pca_2_df).set(title = 'Improved CICIDS2017 Binary Classes PCA Projection') \n",
    "plt.legend(loc = 'center left', bbox_to_anchor = (1, 0.5)) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd0cad7",
   "metadata": {
    "papermill": {
     "duration": 0.017138,
     "end_time": "2023-08-17T10:59:19.897386",
     "exception": false,
     "start_time": "2023-08-17T10:59:19.880248",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 2D-TSNE visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe507f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-17T10:59:19.934710Z",
     "iopub.status.busy": "2023-08-17T10:59:19.934149Z",
     "iopub.status.idle": "2023-08-17T11:44:56.506029Z",
     "shell.execute_reply": "2023-08-17T11:44:56.505175Z"
    },
    "papermill": {
     "duration": 2736.59758,
     "end_time": "2023-08-17T11:44:56.512753",
     "exception": false,
     "start_time": "2023-08-17T10:59:19.915173",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "X = subsample_df.drop(['Label'], axis = 1)\n",
    "y = subsample_df['Label']\n",
    "\n",
    "tsne = TSNE(n_components = 2, n_jobs = -1, verbose = 0, random_state = 0)\n",
    "z = tsne.fit_transform(X) \n",
    "\n",
    "tsne_15_df = pd.DataFrame()\n",
    "tsne_15_df['Label'] = y\n",
    "tsne_15_df['dimension 1'] = z[:, 0]\n",
    "tsne_15_df['dimension 2'] = z[:, 1]\n",
    "\n",
    "sns.scatterplot(x = 'dimension 1', y = 'dimension 2', \n",
    "                hue = tsne_15_df.Label,\n",
    "                palette = sns.color_palette('hls', len(tsne_15_df.Label.value_counts())),\n",
    "                data = tsne_15_df).set(title = 'CICIDS2017 15 Classes T-SNE Projection')\n",
    "plt.legend(loc = 'center left', bbox_to_anchor = (1, 0.5)) \n",
    "plt.show()\n",
    "\n",
    "tsne_2_df = pd.DataFrame()\n",
    "tsne_2_df['Label'] = y\n",
    "tsne_2_df.loc[tsne_2_df.Label != 'BENIGN', 'Label'] = 'ATTACK'\n",
    "tsne_2_df['dimension 1'] = z[:, 0]\n",
    "tsne_2_df['dimension 2'] = z[:, 1]\n",
    "\n",
    "sns.scatterplot(x = 'dimension 1', y = 'dimension 2', \n",
    "                hue = tsne_2_df.Label,\n",
    "                palette = sns.color_palette('hls', 2),\n",
    "                data = tsne_2_df).set(title = 'CICIDS2017 Binary Classes T-SNE Projection') \n",
    "plt.legend(loc = 'center left', bbox_to_anchor = (1, 0.5)) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e5e9f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-17T11:44:56.586677Z",
     "iopub.status.busy": "2023-08-17T11:44:56.585585Z",
     "iopub.status.idle": "2023-08-17T12:22:38.220168Z",
     "shell.execute_reply": "2023-08-17T12:22:38.219101Z"
    },
    "papermill": {
     "duration": 2261.676308,
     "end_time": "2023-08-17T12:22:38.226507",
     "exception": false,
     "start_time": "2023-08-17T11:44:56.550199",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "X = subsample_improved_df.drop(['Label'], axis = 1)\n",
    "y = subsample_improved_df['Label']\n",
    "\n",
    "tsne = TSNE(n_components = 2, n_jobs = -1, verbose = 0, random_state = 0)\n",
    "z = tsne.fit_transform(X) \n",
    "\n",
    "tsne_15_df = pd.DataFrame()\n",
    "tsne_15_df['Label'] = y\n",
    "tsne_15_df['dimension 1'] = z[:, 0]\n",
    "tsne_15_df['dimension 2'] = z[:, 1]\n",
    "\n",
    "sns.scatterplot(x = 'dimension 1', y = 'dimension 2', \n",
    "                hue = tsne_15_df.Label,\n",
    "                palette = sns.color_palette('deep', len(tsne_15_df.Label.value_counts())),\n",
    "                data = tsne_15_df).set(title = 'Improved CICIDS2017 15 Classes T-SNE Projection')\n",
    "plt.legend(loc = 'center left', bbox_to_anchor = (1, 0.5)) \n",
    "plt.show()\n",
    "\n",
    "tsne_2_df = pd.DataFrame()\n",
    "tsne_2_df['Label'] = y\n",
    "tsne_2_df.loc[tsne_2_df.Label != 'BENIGN', 'Label'] = 'ATTACK'\n",
    "tsne_2_df['dimension 1'] = z[:, 0]\n",
    "tsne_2_df['dimension 2'] = z[:, 1]\n",
    "\n",
    "sns.scatterplot(x = 'dimension 1', y = 'dimension 2', \n",
    "                hue = tsne_2_df.Label,\n",
    "                palette = sns.color_palette('deep', 2),\n",
    "                data = tsne_2_df).set(title = 'Improved CICIDS2017 Binary Classes T-SNE Projection') \n",
    "plt.legend(loc = 'center left', bbox_to_anchor = (1, 0.5)) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e8b4bf",
   "metadata": {
    "papermill": {
     "duration": 0.04255,
     "end_time": "2023-08-17T12:22:38.313174",
     "exception": false,
     "start_time": "2023-08-17T12:22:38.270624",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train, validation, and test split [6](#sixth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c46334",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-17T12:22:38.395348Z",
     "iopub.status.busy": "2023-08-17T12:22:38.394530Z",
     "iopub.status.idle": "2023-08-17T12:22:46.550432Z",
     "shell.execute_reply": "2023-08-17T12:22:46.549336Z"
    },
    "papermill": {
     "duration": 8.199971,
     "end_time": "2023-08-17T12:22:46.552883",
     "exception": false,
     "start_time": "2023-08-17T12:22:38.352912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_malicious = improved_df[improved_df.Label != 'BENIGN']\n",
    "all_benign = improved_df[improved_df.Label == 'BENIGN']\n",
    "benign_1M = all_benign.sample(n = 1000000, random_state = 0)\n",
    "\n",
    "train_size = 500000\n",
    "test_size = 500000\n",
    "validation_perc = 0.15\n",
    "\n",
    "# benign trainin and testing\n",
    "Y = benign_1M['Label'].map(lambda x: 1 if (x == 'BENIGN') else -1)\n",
    "labels = benign_1M['Label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(benign_1M.drop(columns = ['Label']),\n",
    "                                                    Y,\n",
    "                                                    train_size = train_size, \n",
    "                                                    test_size = test_size, \n",
    "                                                    shuffle = True, \n",
    "                                                    stratify = Y, \n",
    "                                                    random_state = 0)\n",
    "train_labels, test_labels = labels.loc[y_train.index], labels.loc[y_test.index]\n",
    "\n",
    "# validation and testing\n",
    "X_mal = all_malicious.drop(columns = ['Label'])\n",
    "y_mal = all_malicious['Label'].map(lambda x: 1 if (x == 'Benign') else -1)\n",
    "labels_mal = all_malicious['Label']\n",
    "\n",
    "X_test = pd.concat([X_test, X_mal])\n",
    "y_test = pd.concat([y_test, y_mal])\n",
    "test_labels = pd.concat([test_labels, labels_mal])\n",
    "\n",
    "X_val, X_t, y_val, y_t, label_val, label_t = train_test_split(X_test, \n",
    "                                                              y_test, \n",
    "                                                              test_labels, \n",
    "                                                              train_size = validation_perc, \n",
    "                                                              random_state = 0, \n",
    "                                                              stratify = test_labels, \n",
    "                                                              shuffle = True)\n",
    "\n",
    "print(\"***** Train Data *****\")\n",
    "print(train_labels.value_counts())\n",
    "print(\"***** Validation Data *****\")\n",
    "print(label_val.value_counts())\n",
    "print(\"***** Test Data *****\")\n",
    "print(label_t.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26b5596",
   "metadata": {
    "papermill": {
     "duration": 0.040746,
     "end_time": "2023-08-17T12:22:46.635517",
     "exception": false,
     "start_time": "2023-08-17T12:22:46.594771",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Anomaly score and result evaluation [6](#sixth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4771a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-17T12:22:46.720923Z",
     "iopub.status.busy": "2023-08-17T12:22:46.720547Z",
     "iopub.status.idle": "2023-08-17T12:22:46.733984Z",
     "shell.execute_reply": "2023-08-17T12:22:46.732909Z"
    },
    "papermill": {
     "duration": 0.058486,
     "end_time": "2023-08-17T12:22:46.736324",
     "exception": false,
     "start_time": "2023-08-17T12:22:46.677838",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def anomaly_scores(original, transformed):\n",
    "    sse = np.sum((original - transformed) ** 2, axis = 1) # sum of squared errors\n",
    "    return sse\n",
    "\n",
    "def evaluate_results(y_true, score):\n",
    "    precision, recall, threshold = precision_recall_curve(y_true, score, pos_label = -1)\n",
    "    au_precision_recall = auc(recall, precision)\n",
    "    results = pd.DataFrame({'precision': precision, 'recall': recall})\n",
    "    results['f1'] = 2 * precision * recall / (precision + recall)\n",
    "    max_index = results['f1'].idxmax()\n",
    "    best = results.loc[results['f1'].idxmax()]\n",
    "    best['threshold'] = threshold[max_index]\n",
    "    best['au_precision_recall'] = au_precision_recall\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, score, pos_label = -1)\n",
    "    best['auroc'] = auc(fpr, tpr)\n",
    "    return best\n",
    "\n",
    "def evaluate_predictions(y_true, y_pred):\n",
    "    results = {}\n",
    "    results['precision'] = precision_score(y_true, y_pred, pos_label = -1, zero_division = 0)\n",
    "    results['recall'] = recall_score(y_true, y_pred, pos_label = -1, zero_division = 0)\n",
    "    results['f1'] = f1_score(y_true, y_pred, pos_label = -1, zero_division = 0)\n",
    "    return results\n",
    "\n",
    "def evaluate_test_data(y_true, score, threshold):\n",
    "    y_pred = np.array([1 if score < threshold else -1 for score in score])\n",
    "    results = evaluate_predictions(y_true, y_pred)\n",
    "    precision, recall, threshold = precision_recall_curve(y_true, score, pos_label = -1)\n",
    "    results['au_precision_recall'] = auc(recall, precision)\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, score, pos_label = -1)\n",
    "    results['auroc'] = auc(fpr, tpr)\n",
    "    return results\n",
    "\n",
    "def pca_classifier(scaler, pca, threshold):\n",
    "    def clf(X):\n",
    "        x = scaler.transform(X)\n",
    "        X_pca = pca.transform(x)\n",
    "        X_pca_inv = pca.inverse_transform(X_pca)\n",
    "        score = anomaly_scores(x, X_pca_inv)\n",
    "        return np.array([1 if score < threshold else -1 for score in score])\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54d29cd",
   "metadata": {
    "papermill": {
     "duration": 0.040457,
     "end_time": "2023-08-17T12:22:46.818242",
     "exception": false,
     "start_time": "2023-08-17T12:22:46.777785",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# PCA intrusion detection [5](#fifth), [6](#sixth)\n",
    "\n",
    "## Preprocess with scalar [6](#sixth)\n",
    "\n",
    "## Hyper-parameter tuning [6](#sixth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5eea10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-17T12:22:46.902995Z",
     "iopub.status.busy": "2023-08-17T12:22:46.902592Z",
     "iopub.status.idle": "2023-08-17T13:47:55.250838Z",
     "shell.execute_reply": "2023-08-17T13:47:55.247490Z"
    },
    "papermill": {
     "duration": 5108.395202,
     "end_time": "2023-08-17T13:47:55.255116",
     "exception": false,
     "start_time": "2023-08-17T12:22:46.859914",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import tqdm\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "\n",
    "params = {\n",
    "    'scalers': [StandardScaler(), \n",
    "                RobustScaler(quantile_range = (25, 75)), \n",
    "                QuantileTransformer(output_distribution = 'normal'), \n",
    "                MinMaxScaler(feature_range=(0, 1), copy = True)],\n",
    "    'n_components': list(range(input_dim)),\n",
    "}\n",
    "\n",
    "best_scaler = None\n",
    "best_pca = None\n",
    "best_score = None\n",
    "index = 0\n",
    "results = []\n",
    "\n",
    "for (scaler, n_components) in tqdm.tqdm(list(product(params['scalers'], params['n_components']))):\n",
    "    # print('Scalar', scaler)\n",
    "    x_train = scaler.fit_transform(X_train)\n",
    "    x_val = scaler.transform(X_val)\n",
    "    \n",
    "    # print('Training number of components', n_components, 'PCA', end = '')\n",
    "    n_components = 64\n",
    "    pca = PCA(n_components = n_components, \n",
    "                copy = True, \n",
    "                whiten = False, \n",
    "                svd_solver = 'auto', \n",
    "                tol = 0.0, \n",
    "                iterated_power = 'auto', \n",
    "                random_state = 0)\n",
    "    pca.fit(x_train)\n",
    "    X_val_pca = pca.transform(x_val)\n",
    "    X_val_pca_inv = pca.inverse_transform(X_val_pca)\n",
    "    val_score = anomaly_scores(x_val, X_val_pca_inv)\n",
    "    val_metrics = evaluate_results(y_val, val_score)\n",
    "    val_metrics['n_components'] = n_components\n",
    "    val_metrics['scaler'] = scaler\n",
    "    val_metrics['index'] = index\n",
    "    results.append(val_metrics)\n",
    "    # print('validation auroc', val_metrics['auroc'])\n",
    "    \n",
    "    index += 1\n",
    "    \n",
    "    if best_score is None or val_metrics['auroc'] > best_score['auroc']:\n",
    "        best_scaler = scaler\n",
    "        best_pca = pca\n",
    "        best_score = val_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd35658",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-17T13:47:55.385361Z",
     "iopub.status.busy": "2023-08-17T13:47:55.384729Z",
     "iopub.status.idle": "2023-08-17T13:48:10.658495Z",
     "shell.execute_reply": "2023-08-17T13:48:10.657221Z"
    },
    "papermill": {
     "duration": 15.344049,
     "end_time": "2023-08-17T13:48:10.660880",
     "exception": false,
     "start_time": "2023-08-17T13:47:55.316831",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Best scaler', best_score['scaler'], 'Best number of components', best_score['n_components'])\n",
    "x_t = best_scaler.transform(X_t)\n",
    "X_t_pca = best_pca.transform(x_t)\n",
    "X_t_pca_inv = best_pca.inverse_transform(X_t_pca)\n",
    "test_score = anomaly_scores(x_t, X_t_pca_inv)\n",
    "\n",
    "print('Test performance on all attacks')\n",
    "pprint(evaluate_test_data(y_t, test_score, best_score.threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c75b5f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-17T13:48:10.786727Z",
     "iopub.status.busy": "2023-08-17T13:48:10.786319Z",
     "iopub.status.idle": "2023-08-17T13:48:12.690916Z",
     "shell.execute_reply": "2023-08-17T13:48:12.689358Z"
    },
    "papermill": {
     "duration": 1.970145,
     "end_time": "2023-08-17T13:48:12.693369",
     "exception": false,
     "start_time": "2023-08-17T13:48:10.723224",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'label_t': label_t, 'y_test': y_t, 'test_score': test_score})\n",
    "test_df = df[(df.label_t == 'DoS Slowloris') | (df.label_t == 'DoS Slowhttptest') | (df.label_t == 'BENIGN')]\n",
    "\n",
    "print('Test performance on DoS Slowloris and Slowhttptest')\n",
    "pprint(evaluate_test_data(test_df.y_test.tolist(), test_df.test_score.tolist(), best_score.threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99d95b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-17T13:48:12.824186Z",
     "iopub.status.busy": "2023-08-17T13:48:12.823791Z",
     "iopub.status.idle": "2023-08-17T13:48:41.149054Z",
     "shell.execute_reply": "2023-08-17T13:48:41.147893Z"
    },
    "papermill": {
     "duration": 28.39616,
     "end_time": "2023-08-17T13:48:41.151961",
     "exception": false,
     "start_time": "2023-08-17T13:48:12.755801",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for label in [s for s in improved_df['Label'].unique() if s != 'BENIGN']:\n",
    "    test_df = df[(df.label_t == label) | (df.label_t == 'BENIGN')]\n",
    "    \n",
    "    print('Test performance on', label)\n",
    "    pprint(evaluate_test_data(test_df.y_test.tolist(), test_df.test_score.tolist(), best_score.threshold))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4a7963",
   "metadata": {
    "papermill": {
     "duration": 0.062137,
     "end_time": "2023-08-17T13:48:41.283816",
     "exception": false,
     "start_time": "2023-08-17T13:48:41.221679",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# SHAP explainability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6fff48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-17T13:48:41.414669Z",
     "iopub.status.busy": "2023-08-17T13:48:41.414251Z",
     "iopub.status.idle": "2023-08-17T15:40:02.732307Z",
     "shell.execute_reply": "2023-08-17T15:40:02.729453Z"
    },
    "papermill": {
     "duration": 6681.386779,
     "end_time": "2023-08-17T15:40:02.735327",
     "exception": false,
     "start_time": "2023-08-17T13:48:41.348548",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "subsample_X_t = pd.DataFrame.sample(X_t, frac = 0.01).reset_index(drop = True)\n",
    "\n",
    "# explain the model's predictions using SHAP\n",
    "explainer = shap.Explainer(pca_classifier(best_scaler, best_pca, best_score.threshold), \n",
    "                           masker = shap.maskers.Independent(data = subsample_X_t))\n",
    "shap_values = explainer(subsample_X_t)\n",
    "\n",
    "# visualize the first prediction's explanation\n",
    "shap.plots.waterfall(shap_values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772cad40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-17T15:40:04.044718Z",
     "iopub.status.busy": "2023-08-17T15:40:04.043568Z",
     "iopub.status.idle": "2023-08-17T15:40:06.533410Z",
     "shell.execute_reply": "2023-08-17T15:40:06.532204Z"
    },
    "papermill": {
     "duration": 3.206687,
     "end_time": "2023-08-17T15:40:06.536996",
     "exception": false,
     "start_time": "2023-08-17T15:40:03.330309",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, subsample_X_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe786a08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-17T15:40:07.747064Z",
     "iopub.status.busy": "2023-08-17T15:40:07.745975Z",
     "iopub.status.idle": "2023-08-17T15:40:14.156020Z",
     "shell.execute_reply": "2023-08-17T15:40:14.155022Z"
    },
    "papermill": {
     "duration": 7.023096,
     "end_time": "2023-08-17T15:40:14.158392",
     "exception": false,
     "start_time": "2023-08-17T15:40:07.135296",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.displot(\n",
    "    data = subsample_improved_df,\n",
    "    x = 'Bwd Packet Length Mean', y = 'Packet Length Mean', hue = 'Label',\n",
    ")\n",
    "# Bwd Segment Size Avg, Subflow Bwd Bytes, Protocol, Fwd Packet Length Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673c53b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-17T15:40:15.404902Z",
     "iopub.status.busy": "2023-08-17T15:40:15.403928Z",
     "iopub.status.idle": "2023-08-17T15:40:30.833620Z",
     "shell.execute_reply": "2023-08-17T15:40:30.832346Z"
    },
    "papermill": {
     "duration": 16.035689,
     "end_time": "2023-08-17T15:40:30.836024",
     "exception": false,
     "start_time": "2023-08-17T15:40:14.800335",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.displot(subsample_improved_df, x = 'Bwd Packet Length Mean', hue = 'Label', stat = 'probability')#, kind = 'kde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09b082e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-17T15:40:32.148189Z",
     "iopub.status.busy": "2023-08-17T15:40:32.147793Z",
     "iopub.status.idle": "2023-08-17T15:40:34.528616Z",
     "shell.execute_reply": "2023-08-17T15:40:34.527375Z"
    },
    "papermill": {
     "duration": 3.087626,
     "end_time": "2023-08-17T15:40:34.531027",
     "exception": false,
     "start_time": "2023-08-17T15:40:31.443401",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.displot(subsample_improved_df, x = 'Subflow Bwd Bytes', hue = 'Label', kind = 'kde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d51604",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-17T15:40:35.730079Z",
     "iopub.status.busy": "2023-08-17T15:40:35.729213Z",
     "iopub.status.idle": "2023-08-17T15:40:37.912614Z",
     "shell.execute_reply": "2023-08-17T15:40:37.911479Z"
    },
    "papermill": {
     "duration": 2.77857,
     "end_time": "2023-08-17T15:40:37.915180",
     "exception": false,
     "start_time": "2023-08-17T15:40:35.136610",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.displot(subsample_improved_df, x = 'Protocol', hue = 'Label', kind = 'kde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2279ddd2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-17T15:40:39.240250Z",
     "iopub.status.busy": "2023-08-17T15:40:39.239548Z",
     "iopub.status.idle": "2023-08-17T15:42:07.970435Z",
     "shell.execute_reply": "2023-08-17T15:42:07.969137Z"
    },
    "papermill": {
     "duration": 89.442168,
     "end_time": "2023-08-17T15:42:07.973627",
     "exception": false,
     "start_time": "2023-08-17T15:40:38.531459",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "improved_df.to_csv('cleaned_improved_cicids2017.csv', encoding = 'utf-8', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcee039",
   "metadata": {
    "papermill": {
     "duration": 0.598396,
     "end_time": "2023-08-17T15:42:09.175132",
     "exception": false,
     "start_time": "2023-08-17T15:42:08.576736",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Reference\n",
    "1. <a id='first'></a>[Liu, Lisa, et al. \"Error prevalence in nids datasets: A case study on cic-ids-2017 and cse-cic-ids-2018.\" 2022 IEEE Conference on Communications and Network Security (CNS). IEEE, 2022.](https://ieeexplore.ieee.org/abstract/document/9947235)\n",
    "2. <a id='second'></a>[Lanvin, Maxime, et al. \"Errors in the CICIDS2017 dataset and the significant differences in detection performances it makes.\" International Conference on Risks and Security of Internet and Systems. Cham: Springer Nature Switzerland, 2022.](https://link.springer.com/chapter/10.1007/978-3-031-31108-6_2)\n",
    "3. <a id='third'></a>[Improved CIC-IDS 2017 Documentation](https://intrusion-detection.distrinet-research.be/CNS2022/CICIDS2017.html)\n",
    "4. <a id='fourth'></a>[Error Prevalence in NIDS datasets: A Case Study on CIC-IDS-2017 and CSE-CIC-IDS-2018 (G. Engelen)](https://www.youtube.com/watch?v=sJvZKhw3lYo)\n",
    "5. <a id='fifth'></a>Verkerken, Miel, et al. \"Towards model generalization for intrusion detection: Unsupervised machine learning techniques.\" Journal of Network and Systems Management 30 (2022): 1-25.\n",
    "6. <a id='sixth'></a>[CIC-IDS-2018](https://gitlab.ilabt.imec.be/mverkerk/cic-ids-2018)\n",
    "7. Yang, Li, et al. \"LCCDE: A decision-based ensemble framework for intrusion detection in the internet of vehicles.\" GLOBECOM 2022-2022 IEEE Global Communications Conference. IEEE, 2022.\n",
    "8. [TSNE Visualization Example in Python](https://www.datatechnotes.com/2020/11/tsne-visualization-example-in-python.html)\n",
    "9. [Multicore t-SNE](https://github.com/DmitryUlyanov/Multicore-TSNE)\n",
    "10. [sklearn.manifold.TSNE](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html)\n",
    "11. [What do maskers really do in SHAP package and fit them to train or test?](https://stackoverflow.com/questions/66560839/what-do-maskers-really-do-in-shap-package-and-fit-them-to-train-or-test)\n",
    "12. [Python Statistics Fundamentals: How to Describe Your Data](https://realpython.com/python-statistics/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efca518",
   "metadata": {},
   "source": [
    "Randome Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ebec3a36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use a smaller subset for experimentation\n",
    "subset_size = 10000  # Adjust the size as needed\n",
    "X_subset = X_train[:subset_size]\n",
    "y_subset = y_train[:subset_size]\n",
    "\n",
    "# Train the classifier with the smaller subset\n",
    "clf.fit(X_subset, y_subset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1515200b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, random_state=0, n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "317cce2f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Perform Grid Search\u001b[39;00m\n\u001b[1;32m     11\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(RandomForestClassifier(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), param_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Get the best model\u001b[39;00m\n\u001b[1;32m     15\u001b[0m best_clf \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_estimator_\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:891\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    885\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    886\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    887\u001b[0m     )\n\u001b[1;32m    889\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 891\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    894\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    895\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1392\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1391\u001b[0m     \u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1392\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:838\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    831\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    832\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    833\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    834\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    835\u001b[0m         )\n\u001b[1;32m    836\u001b[0m     )\n\u001b[0;32m--> 838\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    840\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    841\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    857\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    858\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    859\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    860\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:1046\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1044\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1046\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1047\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1050\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1051\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1052\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    860\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 861\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    778\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[0;32m--> 779\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    781\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 572\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py:216\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig):\n\u001b[0;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:680\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    678\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 680\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    683\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    684\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:450\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    439\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m    441\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    442\u001b[0m ]\n\u001b[1;32m    444\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 450\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_joblib_parallel_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    462\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    463\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    464\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    465\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:1056\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1053\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1056\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1057\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1058\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:935\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    934\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 935\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    936\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    937\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py:542\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    540\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 542\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    543\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    544\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/concurrent/futures/_base.py:441\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m--> 441\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 312\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    313\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    # Add other hyperparameters as needed\n",
    "}\n",
    "\n",
    "# Perform Grid Search\n",
    "grid_search = GridSearchCV(RandomForestClassifier(random_state=0, n_jobs=-1), param_grid, cv=3)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model\n",
    "best_clf = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions and evaluate\n",
    "y_pred = best_clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69951bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=50, random_state=0)  # Adjust the number as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12adcd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, random_state=0, n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9012c0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, random_state=0, max_depth=10)  # Adjust the depth as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5983717f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=10, random_state=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_subsample, _, y_train_subsample, _ = train_test_split(X_train, y_train, test_size=0.9, random_state=0)\n",
    "clf.fit(X_train_subsample, y_train_subsample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "516c6c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9996452338718318\n",
      "F1 Score: 0.9992837330487494\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    315942\n",
      "           1       1.00      1.00      1.00    104053\n",
      "\n",
      "    accuracy                           1.00    419995\n",
      "   macro avg       1.00      1.00      1.00    419995\n",
      "weighted avg       1.00      1.00      1.00    419995\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "# Assuming 'improved_df' is your cleaned and preprocessed DataFrame\n",
    "\n",
    "# Separate features and target variable\n",
    "X = improved_df.drop(['Label'], axis=1)\n",
    "y = improved_df['Label']\n",
    "\n",
    "# Convert labels to binary (1 for ATTACK, 0 for BENIGN)\n",
    "y_binary = (y != 'BENIGN').astype(int)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_binary, test_size=0.2, random_state=0)\n",
    "\n",
    "# Reduce the number of trees and enable parallel processing\n",
    "clf = RandomForestClassifier(n_estimators=50, random_state=0, n_jobs=-1)\n",
    "\n",
    "# Train the classifier on a subset of the training data\n",
    "X_train_subsample, _, y_train_subsample, _ = train_test_split(X_train, y_train, test_size=0.9, random_state=0)\n",
    "clf.fit(X_train_subsample, y_train_subsample)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Classification Report:\\n\", report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "54ca7b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9999190466553173\n",
      "F1 Score: 0.9998366154408019\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    315942\n",
      "           1       1.00      1.00      1.00    104053\n",
      "\n",
      "    accuracy                           1.00    419995\n",
      "   macro avg       1.00      1.00      1.00    419995\n",
      "weighted avg       1.00      1.00      1.00    419995\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "# Assuming 'improved_df' is your cleaned and preprocessed DataFrame\n",
    "\n",
    "# Separate features and target variable\n",
    "X = improved_df.drop(['Label'], axis=1)\n",
    "y = improved_df['Label']\n",
    "\n",
    "# Convert labels to binary (1 for ATTACK, 0 for BENIGN)\n",
    "y_binary = (y != 'BENIGN').astype(int)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_binary, test_size=0.2, random_state=0)\n",
    "\n",
    "# Optimize hyperparameters and use parallel processing\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=None, min_samples_leaf=1, random_state=0, n_jobs=-1)\n",
    "\n",
    "# Train the classifier on the entire training set\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Classification Report:\\n\", report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cd51bada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9999190466553173\n",
      "F1 Score: 0.9998366154408019\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    315942\n",
      "           1       1.00      1.00      1.00    104053\n",
      "\n",
      "    accuracy                           1.00    419995\n",
      "   macro avg       1.00      1.00      1.00    419995\n",
      "weighted avg       1.00      1.00      1.00    419995\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "# Assuming 'improved_df' is your cleaned and preprocessed DataFrame\n",
    "\n",
    "# Separate features and target variable\n",
    "X = improved_df.drop(['Label'], axis=1)\n",
    "y = improved_df['Label']\n",
    "\n",
    "# Convert labels to binary (1 for ATTACK, 0 for BENIGN)\n",
    "y_binary = (y != 'BENIGN').astype(int)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_binary, test_size=0.2, random_state=0)\n",
    "\n",
    "# Optimize hyperparameters and use parallel processing\n",
    "clf_2 = RandomForestClassifier(n_estimators=100, max_depth=None, min_samples_leaf=1, random_state=0, n_jobs=-1)\n",
    "\n",
    "# Train the classifier on the entire training set\n",
    "clf_2.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = clf_2.predict(X_test)\n",
    "\n",
    "# Evaluate the performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Classification Report:\\n\", report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a771560d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "\n",
    "model_filename = 'random_forest_model.pkl'\n",
    "joblib.dump(clf_2, model_filename)\n",
    "\n",
    "\n",
    "loaded_model = joblib.load(model_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010458ea",
   "metadata": {},
   "source": [
    "how to use it\n",
    "'loaded_model' to make predictions on new data\n",
    "new_data = ...  # Your new data here\n",
    "predictions = loaded_model.predict(new_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7dc4bf",
   "metadata": {},
   "source": [
    "Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22aee695",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "import pickle\n",
    "\n",
    "# Assuming 'improved_df' is your cleaned and preprocessed DataFrame\n",
    "\n",
    "# Separate features and target variable\n",
    "X = improved_df.drop(['Label'], axis=1)\n",
    "y = improved_df['Label']\n",
    "\n",
    "# Convert labels to binary (1 for ATTACK, 0 for BENIGN)\n",
    "y_binary = (y != 'BENIGN').astype(int)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_binary, test_size=0.2, random_state=0)\n",
    "\n",
    "# Initialize the Support Vector Machine Classifier\n",
    "clf_svm = SVC(kernel='linear', C=1.0)\n",
    "\n",
    "# Train the classifier\n",
    "clf_svm.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_svm = clf_svm.predict(X_test)\n",
    "\n",
    "# Evaluate the performance\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "f1_svm = f1_score(y_test, y_pred_svm)\n",
    "report_svm = classification_report(y_test, y_pred_svm)\n",
    "\n",
    "# Print the results\n",
    "print(\"SVM Accuracy:\", accuracy_svm)\n",
    "print(\"SVM F1 Score:\", f1_svm)\n",
    "print(\"SVM Classification Report:\\n\", report_svm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be03ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained SVM model to a file\n",
    "model_filename_svm = 'svm_model.pkl'\n",
    "with open(model_filename_svm, 'wb') as file:\n",
    "    pickle.dump(clf_svm, file)\n",
    "\n",
    "# Load the SVM model back for later use\n",
    "with open(model_filename_svm, 'rb') as file:\n",
    "    loaded_model_svm = pickle.load(file)\n",
    "\n",
    "# Now you can use 'loaded_model_svm' to make predictions on new data\n",
    "new_data_svm = ...  # Your new data here\n",
    "predictions_svm = loaded_model_svm.predict(new_data_svm)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 17155.453079,
   "end_time": "2023-08-17T15:42:14.124233",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-08-17T10:56:18.671154",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
